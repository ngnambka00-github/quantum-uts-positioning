{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from deep_model import UTSDataset\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from utils import normalize_data, separate_data\n",
    "from quantum_model import QuantumCircuit\n",
    "from deep_model import MeanSquareError, Net, train_model_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26229/4189321069.py:2: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"../configs/\"):\n"
     ]
    }
   ],
   "source": [
    "HOME_PATH = \"../\"\n",
    "with initialize(config_path=\"../configs/\"):\n",
    "    data_cfg = compose(config_name=\"data_path\")\n",
    "data_cfg = OmegaConf.create(data_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_uts_training_path = os.path.join(HOME_PATH, data_cfg.UTS_data.processed_data.filter_train)\n",
    "filter_uts_testing_path = os.path.join(HOME_PATH, data_cfg.UTS_data.processed_data.filter_test)\n",
    "\n",
    "save_model_path = os.path.join(HOME_PATH, data_cfg.model_train.best_model_state)\n",
    "loss_train_path = os.path.join(HOME_PATH, data_cfg.model_train.loss_train)\n",
    "loss_val_path = os.path.join(HOME_PATH, data_cfg.model_train.loss_val)\n",
    "\n",
    "save_data_path_kernel_pca_cosine_64 = os.path.join(HOME_PATH, data_cfg.UTS_data.kernel_pca_cosine_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(filter_uts_training_path).drop(columns=[\"Time\"])\n",
    "data_test = pd.read_csv(filter_uts_testing_path).drop(columns=[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment when run againt\n",
    "\n",
    "# # normalize data from dataframe\n",
    "# uts_filter_train_data = normalize_data(data_train)\n",
    "# uts_filter_test_data = normalize_data(data_test)\n",
    "\n",
    "# # separate data from dataframe\n",
    "# X_train, y_train = separate_data(uts_filter_train_data)\n",
    "# X_test, y_test = separate_data(uts_filter_test_data)\n",
    "\n",
    "# # standard data\n",
    "# scl = StandardScaler()\n",
    "# X_train_scaled = scl.fit_transform(X_train)\n",
    "# X_test_scaled = scl.transform(X_test)\n",
    "\n",
    "# # transformer PCA\n",
    "# transformer = KernelPCA(n_components=64, kernel=\"cosine\", random_state=100)\n",
    "# # transformer = PCA(n_components=0.91, random_state=100)\n",
    "# X_train_transformed = transformer.fit_transform(X_train_scaled)\n",
    "# X_test_transformed = transformer.transform(X_test_scaled)\n",
    "\n",
    "# X_train_transformed.shape, X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(\n",
    "#     save_data_path_kernel_pca_cosine_64, \n",
    "#     np.array(X_train_transformed), \n",
    "#     np.array(y_train), \n",
    "#     np.array(X_test_transformed), \n",
    "#     np.array(y_test)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(save_data_path_kernel_pca_cosine_64)\n",
    "X_train = data['arr_0']\n",
    "y_train = data['arr_1']\n",
    "X_test = data['arr_2']\n",
    "y_test = data['arr_3']\n",
    "\n",
    "datasets = {\n",
    "    \"train\": UTSDataset(X_train, y_train),\n",
    "    \"val\": UTSDataset(X_test, y_test)\n",
    "}\n",
    "\n",
    "## demo 1: batch_size: 32 | 16\n",
    "## demo 2: batch_size: 16 | 4\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(datasets[\"train\"], batch_size=32, shuffle=True, num_workers=os.cpu_count()),\n",
    "    \"val\": DataLoader(datasets[\"val\"], batch_size=4, shuffle=True, num_workers=os.cpu_count())\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"train\": len(datasets[\"train\"]), \n",
    "    \"val\": len(datasets[\"val\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9108, 64), (9108, 2), (388, 64), (388, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 64])\n",
      "Labels batch shape: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(dataloaders[\"train\"]))\n",
    "test_features, test_labels = next(iter(dataloaders[\"val\"]))\n",
    "\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation pi [0.         0.80859375 0.         0.671875   0.         0.65234375\n",
      " 0.         0.5859375  0.         0.80664062 0.73046875 0.\n",
      " 0.         0.67773438 0.         0.89648438 0.         0.8828125 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 417.879x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "import torch\n",
    "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
    "simulator.set_options(device='GPU')\n",
    "\n",
    "circuit = QuantumCircuit(1, simulator, 512, is_add_noise=True)\n",
    "print('Expected value for rotation pi {}'.format(circuit.forward(torch.rand(9))))\n",
    "circuit.circuit.draw('mpl')\n",
    "# circuit.plot(torch.rand(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(quantum=True)\n",
    "# model.load_state_dict(torch.load(save_model_path))\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.004, momentum=0.9, nesterov=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.004, weight_decay=0.001)\n",
    "\n",
    "decayRate = 0.96\n",
    "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "loss_func = MeanSquareError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> phase train: \n",
      "\tBatch: 1/train: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=1'>2</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=3'>4</a>\u001b[0m data_path \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msave_model_path\u001b[39m\u001b[39m\"\u001b[39m: save_model_path, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mloss_train\u001b[39m\u001b[39m\"\u001b[39m: loss_train_path, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=6'>7</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mloss_val\u001b[39m\u001b[39m\"\u001b[39m: loss_val_path,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=7'>8</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nguyennam/Documents/20212/Research/quantum-uts-positioning/src/training_model.ipynb#ch0000011?line=9'>10</a>\u001b[0m train_model_deep(model, loss_func, optimizer, my_lr_scheduler, dataloaders, dataset_sizes, data_path, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/20212/Research/quantum-uts-positioning/src/deep_model.py:128\u001b[0m, in \u001b[0;36mtrain_model_deep\u001b[0;34m(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, data_path, num_epochs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mBatch: \u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mphase\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 128\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m    129\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mType outputs: \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mtype\u001b[39m(outputs))\n\u001b[1;32m    131\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/20212/Research/quantum-uts-positioning/src/deep_model.py:82\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_in(x) \u001b[39m# vao 64 -> ra n_inputs\u001b[39;00m\n\u001b[1;32m     80\u001b[0m quantum_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantum_layer(x_i) \u001b[39mfor\u001b[39;00m x_i \u001b[39min\u001b[39;00m x])\n\u001b[0;32m---> 82\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpre_out(quantum_out\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     83\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_bn(x))\n\u001b[1;32m     84\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_out(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = {\n",
    "    \"save_model_path\": save_model_path, \n",
    "    \"loss_train\": loss_train_path, \n",
    "    \"loss_val\": loss_val_path,\n",
    "}\n",
    "\n",
    "train_model_deep(model, loss_func, optimizer, my_lr_scheduler, dataloaders, dataset_sizes, data_path, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2332e2f7379f093a907912e146c738b6b17d0e5f68fabe19873a9ce22bc37123"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
